import streamlit as st
import pandas as pd

# import os
import io
import matplotlib.pyplot as plt

# from dotenv import load_dotenv

# Importaﾃｧﾃｵes do LangChain atualizadas
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.callbacks import StreamlitCallbackHandler

# --- 1. CONFIGURAﾃﾃグ E VARIﾃ〃EIS DE AMBIENTE ---

# Carregar variﾃ｡veis de ambiente de um arquivo .env
# load_dotenv()
# DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL")
DEEPSEEK_BASE_URL = "https://api.deepseek.com/"


# st_deepseek_api_key = None
# if not st_deepseek_api_key:
#     st_deepseek_api_key = st.text_input(
#         "Por favor, insira sua chave de API DeepSeek:",
#         key="name_input",
#         type="password",
#         help="Vocﾃｪ pode obter sua chave de API em https://deepseek.ai",
#     )


# --- 2. FUNﾃﾃグ DE CRIAﾃﾃグ DO AGENTE (CACHE) ---


# O cache evita recriar o agente a cada interaﾃｧﾃ｣o, a menos que o DataFrame mude.
@st.cache_resource(hash_funcs={pd.DataFrame: lambda _: None})
def setup_agent(df: pd.DataFrame):
    """
    Inicializa a LLM DeepSeek e o Agente Pandas DataFrame.
    """
    if not DEEPSEEK_API_KEY or not DEEPSEEK_BASE_URL:
        st.error(
            "ERRO: As variﾃ｡veis DEEPSEEK_API_KEY e DEEPSEEK_BASE_URL nﾃ｣o estﾃ｣o configuradas."
        )
        st.stop()

    try:
        llm_deepseek = ChatOpenAI(
            model="deepseek-chat",
            api_key=DEEPSEEK_API_KEY,
            base_url=DEEPSEEK_BASE_URL,
            temperature=0.0,
        )

        memory = ConversationBufferMemory(
            memory_key="chat_history", return_messages=True
        )

        AGENT_PREFIX = """
    Vocﾃｪ ﾃｩ um assistente de anﾃ｡lise de dados muito experiente.
    Vocﾃｪ tem acesso a um DataFrame pandas chamado `df`.
    Sua ﾃｺnica ferramenta ﾃｩ o `python_repl` para executar cﾃｳdigo Python.

    - Para responder a perguntas, escreva e execute o cﾃｳdigo Python necessﾃ｡rio para obter a resposta.
    - Se for solicitada uma **visualizaﾃｧﾃ｣o** (ex: "histograma", "grﾃ｡fico de barras", "plot"), 
      **gere o cﾃｳdigo usando a biblioteca `matplotlib.pyplot`**.
    - **Nﾃグ** inclua `st.pyplot()` no cﾃｳdigo que vocﾃｪ gera. Apenas gere o grﾃ｡fico com Matplotlib.
    - Sempre retorne a resposta final em portuguﾃｪs.
    """

        agent = create_pandas_dataframe_agent(
            llm=llm_deepseek,
            df=df,
            # verbose=True,
            verbose=False,
            agent_type="openai-tools",
            memory=memory,
            allow_dangerous_code=True,
            agent_kwargs={"prefix": AGENT_PREFIX},
        )
        return agent

    except Exception as e:
        st.error(
            f"Erro ao inicializar a LLM DeepSeek. Verifique sua chave de API. Detalhe: {e}"
        )
        st.stop()


# --- 3. CONFIGURAﾃﾃグ DA INTERFACE STREAMLIT ---

st.set_page_config(page_title="DeepSeek CSV Analyst com Grﾃ｡ficos", layout="wide")
st.title("投 DeepSeek CSV Analyst (Suporte a Grﾃ｡ficos)")
st.markdown(
    "Peﾃｧa anﾃ｡lises e **grﾃ｡ficos** em linguagem natural! Ex: 'Mostre a distribuiﾃｧﾃ｣o de Idade em um histograma'."
)

# Inicializa o histﾃｳrico de chat e o agente na sessﾃ｣o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "agent" not in st.session_state:
    st.session_state.agent = None


# Solicitar a chave de API
def input_key():
    text_input_container = st.empty()
    st_deepseek_api_key = text_input_container.text_input(
        "Insira sua chave de API DeepSeek",
        key="name_input",
        type="password",
        help="Vocﾃｪ pode obter sua chave de API em https://deepseek.ai",
    )

    if st_deepseek_api_key != "":
        text_input_container.empty()
        return st_deepseek_api_key
        # st.info(t)

DEEPSEEK_API_KEY = input_key()
# st.write(f"Sua chave de API ﾃｩ: {DEEPSEEK_API_KEY}")


# --- 4. UPLOAD DO ARQUIVO CSV ---

uploaded_file = st.sidebar.file_uploader("Upload do Arquivo CSV", type=["csv"])

if uploaded_file:
    try:
        # Decodifica o arquivo e carrega no DataFrame
        df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")))

        st.sidebar.success(
            f"Arquivo **{uploaded_file.name}** carregado! ({len(df)} linhas)"
        )
        st.sidebar.dataframe(df.head(), use_container_width=True)

        # Cria o agente para o DataFrame carregado
        st.session_state.agent = setup_agent(df)

        # Mensagem inicial de boas-vindas
        if not st.session_state.messages:
            st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": "Olﾃ｡! Seu arquivo foi carregado. Pergunte algo como: 'Quais os tipos de dados?' ou 'Crie um grﾃ｡fico de barras da coluna Departamento'.",
                }
            )
    except Exception as e:
        st.sidebar.error(f"Erro ao ler o arquivo CSV: {e}")
        st.session_state.agent = None
else:
    st.info(
        "Por favor, carregue um arquivo CSV na barra lateral para comeﾃｧar a anﾃ｡lise."
    )

# --- 5. Lﾃ敵ICA DO CHAT E PLOTAGEM ---

# Exibe mensagens do histﾃｳrico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Processa nova entrada do usuﾃ｡rio
if prompt := st.chat_input("Digite sua pergunta de anﾃ｡lise ou plotagem..."):
    if st.session_state.agent is None:
        st.warning("Carregue um arquivo CSV antes de fazer uma pergunta.")
        st.stop()

    # Adiciona e exibe a mensagem do usuﾃ｡rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Invoca o Agente e processa a resposta
    with st.chat_message("assistant"):
        st_callback = StreamlitCallbackHandler(st.container())

        with st.spinner("DeepSeek estﾃ｡ pensando e gerando a resposta..."):
            try:
                # O agente invoca a LLM para gerar e executar o cﾃｳdigo Python
                result = st.session_state.agent.invoke(
                    {"input": prompt}, {"callbacks": [st_callback]}
                )

                response_text = result.get(
                    "output", "Nﾃ｣o foi possﾃｭvel gerar uma resposta clara."
                )

                # --- Lﾃ敵ICA DE EXIBIﾃﾃグ DO GRﾃ：ICO (PONTO CENTRAL DA REFATORAﾃﾃグ) ---

                # 1. Captura a figura atual do Matplotlib que o agente criou em background
                fig = plt.gcf()

                # 2. Verifica se a figura tem algum conteﾃｺdo (eixos) para ser exibido
                if fig.get_axes():
                    st.pyplot(fig)  # 3. Renderiza a figura no Streamlit

                # Exibe a resposta textual do agente
                st.markdown(response_text)

                # Adiciona a resposta de texto ao histﾃｳrico
                st.session_state.messages.append(
                    {"role": "assistant", "content": response_text}
                )

            except Exception as e:
                error_message = f"Ocorreu um erro durante a anﾃ｡lise. Tente reformular a pergunta. (Detalhe: {e})"
                st.error(error_message)
                st.session_state.messages.append(
                    {"role": "assistant", "content": error_message}
                )
            finally:
                # Limpa todas as figuras do Matplotlib para a prﾃｳxima execuﾃｧﾃ｣o
                plt.close("all")
